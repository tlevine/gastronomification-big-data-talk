Good day, thank you to everyone for coming, and thank you to BrightTALK
for organizing such a wonderful business intelligence summit.

I'm Thomas Levine. I've been working at the intersection of data analytics
and usability for the past 25 years, and I'm currently the director of product
at CSV. And as you might guess, I have some pretty strong views on data visualization.

(slide)

At CSV, we're *frustrated* with data visualization. Data visualization was
was fine 20 years ago, but it can't handle the enormous scales of big data
that we have today.

(slide)

data, visualize, eyes, &c.

(slide)

Data visualization doesn't have enough bandwidth.

(slide)

To illustrate that, let's take a look at this data table.
These data are about rental apartments. Each horizontal row
in the table is an apartment. The "rowid" is the identification
number, the "price" is the monthly rental price, and the
"updated" is the date at which the information was updated.
We're missing a lot in the "updated" column.

I want you to tell me how many dimensions, or variables, this data table has.

(slide)

You said....

I would say that this data table has three dimensions, one per column.
It's also appropriate to say that the "rowid" column is really an identifier
rather than a dimension.

The point here is that the number of dimensions that a dataset has is
pretty much the same thing as the number of columns that a data table has.

This data table very long and skinny, with only a few dimensions but with
lots of records. That is, it has only a few vertical columns but has lots of horizontal rows.
We call this a "voluminous" spreadsheet; it is very simple, but it has
lots of stuff in it.

(slide)

Compare that to this data table. This one only has five rows, so we only have
data about five apartments. On the other hand, it has many columns, so we have
a lot of information about each apartment. We call this a "complex" spreadsheet.

(slide)

What happens when we have a spreadsheet that is both voluminous and complex?
That's a big spreadsheet. The challenge with today's big data is that it is
both high-volume and high-complexity.

(slide)

It is absolutely impossible for anyone to understand a big dataset. In order
to understand it, we have to reduce its volume, simplify it, and work in a team.

(slide)

Reducing the data volume is relatively easy.
We reduce the data volume with aggregations, or statistics, like means, medians,
counts, and so on. Smart people pick this up pretty quickly.

(slide)

Reducing the complexity is hard. We need to use advanced modeling techniques
to for this, and you have to be careful about choosing the correct model.
There's a lot of new technology that is starting to make this a bit easier,
but you basically need to be a data scientist or statistician in order to do
this well.

(slide)

I propose that we don't need to reduce the complexity. Instead, we just need
to put more dimensions into our plots. Let me show you what I mean by that.

I'm going to do another vote. Please tell me how many dimensions are in this
scatterplot. I'll tell you what the plot is about after we do the vote.

(slide)

This plot has three dimensions....

Now, let's think about how this plot scales with big data.
If we have voluminous data, we just need to add more dots. That's easy.
But what do we do if we have complex data, with more than a few variables?
Maybe we could change the style of dot or add lines, but that would only
give us a couple more dimensions; there's no way that we'll fit 100 dimensions,
or even just 20 dimensions on here.

(slide)

So what do people do today about the big data problem?
It usually falls into one of these two groups.
In most companies, the data just goes to waste because the organization
doesn't have the tools to work with such complex data.
If a company does manage to take advantage of the data, it's only because they
had a very important question that was worth throwing lots of people and money at.

(slide)

But we do things a bit differently.

(slide)

Let's go back to this slide from earlier. Visualization doesn't have enough
bandwidth for today's complex big data. What if we tried using more than just
visualization?

(slide)

Our earlier big data products focused on adding the sense of sound, through
a music video paradigm.

(slide)

One of our earlier projects was this video about the finances of the United
States federal government. I have linked to the video in the "attachments"
section, and this next slide has other directions in case that doesn't work
for whatever reason.

The video....

As you see and hear, by adding sound, we were able to communicate very complex data.

(slide)

We wrote this video in R. We think R is a really good tool for making data
music videos....

(slide)

Our R-based data music product is called data-driven rhythms. We find it to
be very intuitive for people who are used to working with R. For those who
know R, this is a sample of how we use the package....

(slide)

Unfortunately, most people don't know R.
Data-driven rhythms is a great tool for data scientists, but we can't expect
everyone to become a data scientist overnight.
On the other hand, everyone knows how to use spreadsheets.
Our more popular data music product is called "sheetmusic"; it lets you compose
data-driven music inside of a spreadsheet. Let's see how that works.

This spreadsheet contains some cells with codes in them and an image of some
sheetmusic. The sheetmusic was actually generated from the data.

(slide)

Here we can see how the spreadsheet corresponds to the sheet music....

(slide)

Sheetmusic is a full-fleged music synthesizer that lets you compose music
with spreadsheet functions. Afterwards, you can play the music, export it
as a sound file, or print it as sheetmusic.

(On to the "Case study" slide)

Now I'll show you how one of our clients uses sheetmusic.

We helped a large technology company expand its marketing analytics team
to meet an unexpected increase in business. We needed to grow the team
quickly
